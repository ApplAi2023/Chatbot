{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzd8R8viOdSW"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np \n",
        "import pickle\n",
        "import json\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , Activation , Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np-H60AKSGFO",
        "outputId": "a07d739b-4a21-41b2-d702-7640c0e041eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKm6S_ElmK8w"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpQEQ9jySFOu",
        "outputId": "c28eda07-464f-414b-abd0-d4901e4f0e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ],
      "source": [
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE8N-QLFyGwU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPx7-r1QmQRl"
      },
      "outputs": [],
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f28AFWoDmthv"
      },
      "outputs": [],
      "source": [
        "data = pd.read_json('applai_dataa.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukUWtuz8ODS7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c29505-db7d-4af0-97c8-78cc75ce57cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Series.keys of 0    {'tag': 'greetings', 'patterns': ['hello', 'hi...\n",
              "1    {'tag': 'good bye', 'patterns': ['bye', 'bye b...\n",
              "2    {'tag': 'name', 'patterns': ['what is your nam...\n",
              "3    {'tag': 'applai`s trainings time', 'patterns':...\n",
              "4    {'tag': 'applai`s trainings place', 'patterns'...\n",
              "5    {'tag': 'applai`s departments', 'patterns': ['...\n",
              "6    {'tag': 'applai`s trainings place', 'patterns'...\n",
              "7    {'tag': 'applai`s campaigns', 'patterns': ['Do...\n",
              "8    {'tag': 'general information about applai', 'p...\n",
              "9    {'tag': 'applai's training content', 'patterns...\n",
              "Name: applai, dtype: object>"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ],
      "source": [
        "data['applai'].keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UErVQ4Rm48t"
      },
      "outputs": [],
      "source": [
        "words=[]\n",
        "documents=[]\n",
        "classes=[]\n",
        "Ignore_letters=['?','!','.',',']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpwOkq8BoZuo"
      },
      "outputs": [],
      "source": [
        "for i in data['applai']:\n",
        "  for pattern in i['patterns']:\n",
        "    word_list = nltk.word_tokenize(pattern)\n",
        "#word_tokenize using for separating each word in the sentence in each pattern\n",
        "    words.extend(word_list)\n",
        "    documents.append((word_list, i['tag']))\n",
        "#so we could know that this word in the pattern belong to this tag\n",
        "    if i['tag'] not in classes :\n",
        "      classes.append(i['tag'])       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f56G5lstISv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0UurKwUuM0p",
        "outputId": "6a9f4416-5428-42ab-ba63-afdec1cf0465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['hello'], 'greetings')\n"
          ]
        }
      ],
      "source": [
        "print(documents[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAWu8mp1ST5p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyn2uwRuYdS8"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "#wnl = WordNetLemmatizer()\n",
        "\n",
        "lemmatized_words = [[lemmatizer.lemmatize(word) for word in l if word not in Ignore_letters] for l in words ]\n",
        "words = sorted(set(words))\n",
        "classes = sorted(set(classes))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuOECJqPZ8PI",
        "outputId": "17180009-d550-4ff1-9dca-d6c03f0d5720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"'s\", '?', 'AI', 'Ain', 'Can', 'Does', 'For', 'How', 'I', 'Is', 'Shams', 'University', 'What', 'When', '`', 'activities', 'and', 'any', 'applai', 'are', 'at', 'been', 'branches', 'bye', 'call', 'campaigns', 'club', 'content', 'could', 'cover', 'created', 'day', 'deep', 'departments', 'does', 'established', 'explain', 'find', 'go', 'good', 'greetings', 'has', 'have', 'held', 'hello', 'hey', 'hi', 'hold', 'how', 'in', 'is', 'learning', 'leaving', 'm', 'machine', 'many', 'me', 'name', 'now', 'offer', 'offered', 'other', 'place', 'related', 's', 'should', 'tell', 'the', 'there', 'topic', 'training', 'trainings', 'up', 'was', 'what', 'when', 'where', 'who', 'will', 'working', 'years', 'you', 'your']\n"
          ]
        }
      ],
      "source": [
        "print(words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMnqA-MIPgMc",
        "outputId": "a66cc160-7cd5-4ca3-c416-50b044034fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"applai's training content\", 'applai`s campaigns', 'applai`s departments', 'applai`s trainings place', 'applai`s trainings time', 'general information about applai', 'good bye', 'greetings', 'name']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkNn0BRwPZOk"
      },
      "outputs": [],
      "source": [
        "pickle.dump(words,open('words.pkl','wb'))\n",
        "pickle.dump(classes,open('classes.pkl','wb'))\n",
        "#to save the lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg-YNdlLTuJE"
      },
      "outputs": [],
      "source": [
        "training=[]\n",
        "output_empty=[0] * len(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJylOcrwW1t0"
      },
      "outputs": [],
      "source": [
        "for document in documents:\n",
        "  bag=[]\n",
        "  word_patterns=document[0]\n",
        "  word_patterns = [lemmatizer.lemmatize(word.lower()) for word in word_patterns]\n",
        "  for word in words:\n",
        "    bag.append(1) if word in word_patterns else bag.append(0)\n",
        "\n",
        "  output_row = list(output_empty)\n",
        "  output_row[classes.index(document[1])] = 1\n",
        "  training.append([bag , output_row])  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvknG1X2Zq0U",
        "outputId": "b2179dcc-038e-49ac-e019-f1e6aac3bc8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-198-cc0bc1dae1db>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  training = np.array(training)\n"
          ]
        }
      ],
      "source": [
        "random.shuffle(training)\n",
        "training = np.array(training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkoNGUisZ5pr"
      },
      "outputs": [],
      "source": [
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kG-BRaSaI4n",
        "outputId": "aea9168f-0da5-4c61-b291-97cbb636897f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2763 - accuracy: 0.0256\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.1835 - accuracy: 0.1282\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0407 - accuracy: 0.3846\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8664 - accuracy: 0.4359\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0041 - accuracy: 0.3333\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8502 - accuracy: 0.3590\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7155 - accuracy: 0.4872\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5577 - accuracy: 0.5385\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4781 - accuracy: 0.6923\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4706 - accuracy: 0.6154\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4146 - accuracy: 0.5897\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4445 - accuracy: 0.5128\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1902 - accuracy: 0.7179\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1945 - accuracy: 0.6923\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.2357 - accuracy: 0.6410\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8746 - accuracy: 0.6923\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8353 - accuracy: 0.7949\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7299 - accuracy: 0.7179\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.7949\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7180 - accuracy: 0.7436\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7975 - accuracy: 0.7949\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.8205\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.8462\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.8205\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8462\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7949\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8718\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8974\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8205\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8718\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.9231\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8974\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8718\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8462\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.9487\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8974\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.8974\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8718\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3105 - accuracy: 0.8718\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2208 - accuracy: 0.9744\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.9487\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9487\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9744\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1024 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1550 - accuracy: 0.9487\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.9231\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9487\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9744\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9487\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2570 - accuracy: 0.9487\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9744\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2183 - accuracy: 0.9487\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9231\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1599 - accuracy: 0.9487\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1121 - accuracy: 0.9744\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9487\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.8718\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9744\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9744\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.9487\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9487\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9231\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9744\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9744\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.9744\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9487\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1139 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9744\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.9744\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9487\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9744\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9487\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1138 - accuracy: 0.9487\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9231\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9744\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 0.9744\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9487\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.9744\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.9744\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.9487\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1024 - accuracy: 0.9744\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9744\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9744\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),),activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='Softmax'))\n",
        "sgd = tf.keras.optimizers.legacy.SGD(\n",
        "    learning_rate=0.01,decay=1e-6, \n",
        "    momentum=0.9,\n",
        "    nesterov=False,\n",
        "    name='SGD'\n",
        ")\n",
        "model.compile(loss='categorical_crossentropy', optimizer = sgd , metrics=['accuracy'])\n",
        "\n",
        "hist=model.fit(np.array(train_x),np.array(train_y),epochs = 100 , batch_size = 5 , verbose = 1 )\n",
        "model.save('applai_chatbot_model.h5',hist)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9TSfbCDTPSp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNkOzlDN90pg",
        "outputId": "b741807b-c44b-4d5e-a2a6-496db1a5356c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: streamlit-chat in /usr/local/lib/python3.8/dist-packages (0.0.2.1)\n",
            "Requirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.8/dist-packages (from streamlit-chat) (1.19.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (6.0.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (7.1.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (13.3.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (0.10.2)\n",
            "Requirement already satisfied: semver in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (2.13.0)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (1.3.5)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (1.5)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (4.5.0)\n",
            "Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (1.22.4)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (2.3.0)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (2.8.2)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (5.3.0)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (0.8.0)\n",
            "Requirement already satisfied: requests>=2.4 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (2.25.1)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (4.2.2)\n",
            "Requirement already satisfied: validators>=0.2 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (0.20.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (7.1.2)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (1.5.1)\n",
            "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (1.0.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (3.19.6)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (6.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (3.1.31)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=0.63->streamlit-chat) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=0.63->streamlit-chat) (2.11.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=0.63->streamlit-chat) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=0.63->streamlit-chat) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from gitpython!=3.1.19->streamlit>=0.63->streamlit-chat) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=1.4->streamlit>=0.63->streamlit-chat) (3.14.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25->streamlit>=0.63->streamlit-chat) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil->streamlit>=0.63->streamlit-chat) (1.15.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit>=0.63->streamlit-chat) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit>=0.63->streamlit-chat) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit>=0.63->streamlit-chat) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit>=0.63->streamlit-chat) (2022.12.7)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in /usr/local/lib/python3.8/dist-packages (from rich>=10.11.0->streamlit>=0.63->streamlit-chat) (2.14.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from rich>=10.11.0->streamlit>=0.63->streamlit-chat) (2.2.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from validators>=0.2->streamlit>=0.63->streamlit-chat) (4.4.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit>=0.63->streamlit-chat) (5.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->altair>=3.2.0->streamlit>=0.63->streamlit-chat) (2.0.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.63->streamlit-chat) (5.12.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.63->streamlit-chat) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.63->streamlit-chat) (0.19.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.8/dist-packages (from markdown-it-py<3.0.0,>=2.1.0->rich>=10.11.0->streamlit>=0.63->streamlit-chat) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit-chat"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t3Ehh3j67dyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ-gZKKISDIn"
      },
      "outputs": [],
      "source": [
        "# #%%writefile app.py\n",
        "# import random\n",
        "# import json\n",
        "# import pickle\n",
        "# import numpy as np\n",
        "# import nltk\n",
        "# from nltk.stem import WordNetLemmatizer\n",
        "# from tensorflow.keras.models import load_model\n",
        "# import streamlit as st\n",
        "# import tensorflow as tf\n",
        "# from keras.models import load_model\n",
        "# import nltk\n",
        "# # %%writefile app.py\n",
        "# import streamlit as st\n",
        "# from streamlit_chat import message\n",
        "\n",
        "# # message(\"My message\") \n",
        "# # message(\"Hello bot!\", is_user=True)  # align's the message to the right\n",
        "\n",
        "# from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "# lemmatizer = WordNetLemmatizer()\n",
        "# intents = json.loads(open('applai_dataa.json').read())\n",
        "# words = pickle.load(open('words.pkl', 'rb'))\n",
        "# classes = pickle.load(open('classes.pkl', 'rb'))\n",
        "# model = load_model('applai_chatbot_model.h5')\n",
        "# def clean_up_sentence (sentence):\n",
        "#   sentence_words=nltk.word_tokenize (sentence)\n",
        "#   sentence_words= [lemmatizer.lemmatize (word) for word in sentence_words]\n",
        "#   return sentence_words\n",
        "# def bag_of_words (sentence):\n",
        "#   sentence_words = clean_up_sentence (sentence)\n",
        "#   bag = [0] * len(words)\n",
        "#   for w in sentence_words:\n",
        "#     for i, word in enumerate(words):\n",
        "#       if word == w:\n",
        "#         bag[i] = 1\n",
        "#     return np.array(bag)  \n",
        "# def predict_class(sentence):\n",
        "#   bow = bag_of_words (sentence)\n",
        "#   res = model.predict(np.array([bow]))[0]\n",
        "#   ERROR_THRESHOLD = 0.25\n",
        "#   results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "#   results.sort(key=lambda x: x[1], reverse=True)\n",
        "#   return_list = []\n",
        "#   for r in results:\n",
        "#     return_list.append({'applai': classes [r[0]], 'probability': str(r[1])})\n",
        "#   return return_list\n",
        "# model = tf.keras.models.load_model('applai_chatbot_model.h5')\n",
        "# nltk.download('punkt')\n",
        "\n",
        "\n",
        "# def get_response(intents_list, intents_json):\n",
        "#   tag = intents_list[0]['applai'] \n",
        "#   list_of_intents = intents_json['applai']\n",
        "#   for i in list_of_intents:\n",
        "#     if i['tag'] == tag:\n",
        "#       result = random.choice(i['responses'])\n",
        "#       break\n",
        "#   return result\n",
        "# def generate_response(user_input):\n",
        "#     # Preprocess user input\n",
        "#     user_input = user_input.lower()\n",
        "#     tokens = nltk.word_tokenize(user_input)\n",
        "\n",
        "#     # Convert tokens to a sequence of word indices\n",
        "#     word_indices = []\n",
        "#     for word in tokens:\n",
        "#         if word in word_index:\n",
        "#             word_indices.append(word_index[word])\n",
        "#         else:\n",
        "#             word_indices.append(word_index['<unk>'])\n",
        "\n",
        "#     # Pad sequence to max length\n",
        "#     padded_seq = pad_sequences([word_indices], maxlen=max_seq_length,\n",
        "#                                padding='post', truncating='post')\n",
        "\n",
        "#     # Generate response\n",
        "#     response_idx = np.argmax(model.predict(padded_seq), axis=-1)[0]\n",
        "#     response = index_word[response_idx]\n",
        "\n",
        "#     return response\n",
        "# def resp (user_input):\n",
        "#   x=predict_class(user_input)\n",
        "#   response = get_response(x,intents)\n",
        "#   st.write('ApplAI Bot: ',response)\n",
        "\n",
        "\n",
        "\n",
        "# i=0\n",
        "# import uuid\n",
        "\n",
        "\n",
        "# st.title('Welcome To Applai Chatbot')\n",
        "# st.sidebar.image(\"ApplAiOnly_Logo.png\", use_column_width=True)\n",
        "# conversation_active=True\n",
        "\n",
        "\n",
        "\n",
        "# # sub=False\n",
        "# # user_input=\" \"\n",
        "# # flag=True\n",
        "# # while user_input!='Exit' :\n",
        "# #   if flag:\n",
        "# #     user_input = st.text_input('Enter a question:')\n",
        "# #     sub=st.button('Get answer')\n",
        "# #     #flag=False\n",
        " \n",
        "# #   if sub :\n",
        "# #     flag=True\n",
        "# #     sub=False\n",
        "# #     x=predict_class(user_input)\n",
        "# #     response = get_response(x,intents)\n",
        "# #     st.write(response)\n",
        "# once = True\n",
        "# sub = False\n",
        "\n",
        "# if once:\n",
        "    \n",
        "#     user_input = st.text_input('Enter a question:')\n",
        "#     sub = st.button('Get answer')\n",
        "\n",
        "# if sub:\n",
        "#     once = False\n",
        "#     sub = not sub\n",
        "#     x = predict_class(user_input)\n",
        "#     response = get_response(x, intents)\n",
        "#     st.write(response)\n",
        "# if not once:\n",
        "#   user_input = st.text_input('Enter another question:')\n",
        "#   sub = st.button('Get answer',str(uuid.uuid4()))\n",
        "\n",
        "#     #user_input2 = st.text_input('Enter another question:')\n",
        "#     #sub2=st.button('Get answer',key=2)\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras.models import load_model\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "import nltk\n",
        "# %%writefile app.py\n",
        "import streamlit as st\n",
        "from streamlit_chat import message\n",
        "\n",
        "# message(\"My message\") \n",
        "# message(\"Hello bot!\", is_user=True)  # align's the message to the right\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "intents = json.loads(open('applai_dataa.json').read())\n",
        "words = pickle.load(open('words.pkl', 'rb'))\n",
        "classes = pickle.load(open('classes.pkl', 'rb'))\n",
        "model = load_model('applai_chatbot_model.h5')\n",
        "def clean_up_sentence (sentence):\n",
        "  sentence_words=nltk.word_tokenize (sentence)\n",
        "  sentence_words= [lemmatizer.lemmatize (word) for word in sentence_words]\n",
        "  return sentence_words\n",
        "def bag_of_words (sentence):\n",
        "  sentence_words = clean_up_sentence (sentence)\n",
        "  bag = [0] * len(words)\n",
        "  for w in sentence_words:\n",
        "    for i, word in enumerate(words):\n",
        "      if word == w:\n",
        "        bag[i] = 1\n",
        "    return np.array(bag)  \n",
        "def predict_class(sentence):\n",
        "  bow = bag_of_words (sentence)\n",
        "  res = model.predict(np.array([bow]))[0]\n",
        "  ERROR_THRESHOLD = 0.25\n",
        "  results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "  results.sort(key=lambda x: x[1], reverse=True)\n",
        "  return_list = []\n",
        "  for r in results:\n",
        "    return_list.append({'applai': classes [r[0]], 'probability': str(r[1])})\n",
        "  return return_list\n",
        "model = tf.keras.models.load_model('applai_chatbot_model.h5')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "def get_response(intents_list, intents_json):\n",
        "  tag = intents_list[0]['applai'] \n",
        "  list_of_intents = intents_json['applai']\n",
        "  for i in list_of_intents:\n",
        "    if i['tag'] == tag:\n",
        "      result = random.choice(i['responses'])\n",
        "      break\n",
        "  return result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ccHH3AWCZ-d",
        "outputId": "d79e7b19-f4b4-4545-de78-d209d9d730d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "def chatbot(input, history=[]):\n",
        "    x = predict_class(input)\n",
        "    response = get_response(x, intents)\n",
        "  \n",
        "    #output = openai_chat(input)\n",
        "    history.append((input, response))\n",
        "    return history, history\n",
        "add_image = \"body {background-image: 'ApplAiOnly_Logo.png';}\"\n",
        "#with gr.Blocks(css=\".gradio-container {background-image: url('file=clouds.jpg')}\") as demo:\n",
        "#css=\".gradio-container {background-image: url('file=ApplAiOnly_Logo.png')}\"\n",
        "iface=gr.Interface(fn = chatbot,logo='ApplAiOnly_Logo.png',title=\"Welcome To ApplAI ChatBot\"\n",
        ",\n",
        "             inputs = [\"text\",'state'],\n",
        "             outputs = [\"chatbot\",'state'])\n",
        "\n",
        "\n",
        "iface.launch()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "U4K4EOMZCFqc",
        "outputId": "b3888b6b-efeb-4800-85d9-eb136354db11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-219-66892b3b3b14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0miface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logo\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ApplAiOnly_Logo.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0miface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Interface' object has no attribute 'metadata'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gr.__version__)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0bTWg0kbVzT",
        "outputId": "3176c038-a21e-4db0-e0b7-a0220145bf89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import streamlit as st\n",
        "# from streamlit_chat import message as st_message\n",
        "# if \"history\" not in st.session_state:\n",
        "#     st.session_state.history = []\n",
        "\n",
        "# st.title('Welcome To Applai Chatbot')\n",
        "# st.sidebar.image(\"ApplAiOnly_Logo.png\", use_column_width=True)\n",
        "\n",
        "\n",
        "# def generate_answer():\n",
        "#     tokenizer, model = get_models()\n",
        "#     user_message = st.session_state.input_text\n",
        "#     inputs = tokenizer(st.session_state.input_text, return_tensors=\"pt\")\n",
        "#     result = model.generate(**inputs)\n",
        "#     message_bot = tokenizer.decode(\n",
        "#         result[0], skip_special_tokens=True\n",
        "#     )  # .replace(\"<s>\", \"\").replace(\"</s>\", \"\")\n",
        "\n",
        "#     st.session_state.history.append({\"message\": user_message, \"is_user\": True})\n",
        "#     st.session_state.history.append({\"message\": message_bot, \"is_user\": False})\n",
        "\n",
        "\n",
        "# st.text_input(\"Talk to the bot\", key=\"input_text\", on_change=generate_answer)\n",
        "\n",
        "# for chat in st.session_state.history:\n",
        "#     st_message(**chat)  # unpacking"
      ],
      "metadata": {
        "id": "sN3kKIeMusrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #%%writefile app.py\n",
        "\n",
        "# import streamlit as st\n",
        "# import random\n",
        "# import json\n",
        "# import pickle\n",
        "# import numpy as np\n",
        "# import nltk\n",
        "# from nltk.stem import WordNetLemmatizer\n",
        "# from tensorflow.keras.models import load_model\n",
        "# import streamlit as st\n",
        "# import tensorflow as tf\n",
        "# from keras.models import load_model\n",
        "# import nltk\n",
        "# import uuid\n",
        "\n",
        "# from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "# lemmatizer = WordNetLemmatizer()\n",
        "# intents = json.loads(open('applai_dataa.json').read())\n",
        "# words = pickle.load(open('words.pkl', 'rb'))\n",
        "# classes = pickle.load(open('classes.pkl', 'rb'))\n",
        "# model = load_model('applai_chatbot_model.h5')\n",
        "# def clean_up_sentence (sentence):\n",
        "#   sentence_words=nltk.word_tokenize (sentence)\n",
        "#   sentence_words= [lemmatizer.lemmatize (word) for word in sentence_words]\n",
        "#   return sentence_words\n",
        "# def bag_of_words (sentence):\n",
        "#   sentence_words = clean_up_sentence (sentence)\n",
        "#   bag = [0] * len(words)\n",
        "#   for w in sentence_words:\n",
        "#     for i, word in enumerate(words):\n",
        "#       if word == w:\n",
        "#         bag[i] = 1\n",
        "#     return np.array(bag)  \n",
        "# def predict_class(sentence):\n",
        "#   bow = bag_of_words (sentence)\n",
        "#   res = model.predict(np.array([bow]))[0]\n",
        "#   ERROR_THRESHOLD = 0.25\n",
        "#   results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "#   results.sort(key=lambda x: x[1], reverse=True)\n",
        "#   return_list = []\n",
        "#   for r in results:\n",
        "#     return_list.append({'applai': classes [r[0]], 'probability': str(r[1])})\n",
        "#   return return_list\n",
        "# model = tf.keras.models.load_model('applai_chatbot_model.h5')\n",
        "# nltk.download('punkt')\n",
        "\n",
        "\n",
        "# def get_response(intents_list, intents_json):\n",
        "#   tag = intents_list[0]['applai'] \n",
        "#   list_of_intents = intents_json['applai']\n",
        "#   for i in list_of_intents:\n",
        "#     if i['tag'] == tag:\n",
        "#       result = random.choice(i['responses'])\n",
        "#       break\n",
        "#   return result\n",
        "# def generate_response(user_input):\n",
        "#     # Preprocess user input\n",
        "#     user_input = user_input.lower()\n",
        "#     tokens = nltk.word_tokenize(user_input)\n",
        "\n",
        "#     # Convert tokens to a sequence of word indices\n",
        "#     word_indices = []\n",
        "#     for word in tokens:\n",
        "#         if word in word_index:\n",
        "#             word_indices.append(word_index[word])\n",
        "#         else:\n",
        "#             word_indices.append(word_index['<unk>'])\n",
        "\n",
        "#     # Pad sequence to max length\n",
        "#     padded_seq = pad_sequences([word_indices], maxlen=max_seq_length,\n",
        "#                                padding='post', truncating='post')\n",
        "\n",
        "#     # Generate response\n",
        "#     response_idx = np.argmax(model.predict(padded_seq), axis=-1)[0]\n",
        "#     response = index_word[response_idx]\n",
        "\n",
        "#     return response\n",
        "\n",
        "# # Set page title\n",
        "# ####################################################################\n",
        "# st.set_page_config(page_title=\"'Welcome To Applai Chatbot'\")\n",
        "\n",
        "# # Define a function to handle user input and bot responses\n",
        "# def run_chatbot():\n",
        "#     chat_history = []\n",
        "    \n",
        "#     while True:\n",
        "#         key1 = str(uuid.uuid4())\n",
        "#         key2 = str(uuid.uuid4())\n",
        "#         key3 = str(uuid.uuid4())\n",
        "#         key4 = str(uuid.uuid4())\n",
        "#         # Create an input field for the user to enter their question\n",
        "#         user_input = st.text_input(\"Enter your question here:\",key=key1)\n",
        "        \n",
        "#         # Create a button to submit the user's question\n",
        "#         if st.button(\"Ask\",key=key2):\n",
        "#             if user_input:\n",
        "#                 # Add the user's question to the chat history\n",
        "#                 chat_history.append(\"You: \" + user_input)\n",
        "                \n",
        "#                 # Call the chatbot function to generate a response\n",
        "#                 x=predict_class(user_input)\n",
        "#                 response = get_response(x,intents)\n",
        "                \n",
        "                \n",
        "                \n",
        "#                 # Add the bot's response to the chat history\n",
        "#                 chat_history.append(\"Bot: \" + response)\n",
        "            \n",
        "#         # Display the chat history\n",
        "#         #st.write(\"\\n\".join(chat_history))\n",
        "\n",
        "# # Run the chatbot function\n",
        "# run_chatbot()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gh3UCE_VFbbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import streamlit as st\n",
        "\n",
        "# # Define a function to generate the chatbot response\n",
        "# def generate_response(input_text):\n",
        "#     # Add your chatbot logic here\n",
        "#     return \"You said: \" + input_text\n",
        "\n",
        "# # Loop to repeatedly prompt the user for input and generate a response\n",
        "# conversation_active = True\n",
        "# while conversation_active:\n",
        "#     # Create a text box for user input\n",
        "#     user_input = st.text_input(\"Enter your question or message here:\")\n",
        "\n",
        "#     # Create a button that the user can click to submit their input\n",
        "#     submit_button = st.button(\"Submit\")\n",
        "\n",
        "#     # If the user has submitted input, generate and display the chatbot response\n",
        "#     if submit_button:\n",
        "#         response = generate_response(user_input)\n",
        "#         st.write(response)\n",
        "\n",
        "#         # Prompt the user for another question\n",
        "#         user_input = st.text_input(\"Enter another question or message, or leave blank to end the conversation:\")\n",
        "#         if user_input == \"\":\n",
        "#             conversation_active = False"
      ],
      "metadata": {
        "id": "5LDhlu1LBfy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNI_8_500N-4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# #%%writefile app.py\n",
        "# import random\n",
        "# import json\n",
        "# import pickle\n",
        "# import numpy as np\n",
        "# import nltk\n",
        "# from nltk.stem import WordNetLemmatizer\n",
        "# from tensorflow.keras.models import load_model\n",
        "# import streamlit as st\n",
        "# import tensorflow as tf\n",
        "# from keras.models import load_model\n",
        "# import nltk\n",
        "\n",
        "# from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "# lemmatizer = WordNetLemmatizer()\n",
        "# intents = json.loads(open('applai_dataa.json').read())\n",
        "# words = pickle.load(open('words.pkl', 'rb'))\n",
        "# classes = pickle.load(open('classes.pkl', 'rb'))\n",
        "# model = load_model('applai_chatbot_model.h5')\n",
        "# def clean_up_sentence (sentence):\n",
        "#   sentence_words=nltk.word_tokenize (sentence)\n",
        "#   sentence_words= [lemmatizer.lemmatize (word) for word in sentence_words]\n",
        "#   return sentence_words\n",
        "# def bag_of_words (sentence):\n",
        "#   sentence_words = clean_up_sentence (sentence)\n",
        "#   bag = [0] * len(words)\n",
        "#   for w in sentence_words:\n",
        "#     for i, word in enumerate(words):\n",
        "#       if word == w:\n",
        "#         bag[i] = 1\n",
        "#     return np.array(bag)  \n",
        "# def predict_class(sentence):\n",
        "#   bow = bag_of_words (sentence)\n",
        "#   res = model.predict(np.array([bow]))[0]\n",
        "#   ERROR_THRESHOLD = 0.25\n",
        "#   results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "#   results.sort(key=lambda x: x[1], reverse=True)\n",
        "#   return_list = []\n",
        "#   for r in results:\n",
        "#     return_list.append({'applai': classes [r[0]], 'probability': str(r[1])})\n",
        "#   return return_list\n",
        "# model = tf.keras.models.load_model('applai_chatbot_model.h5')\n",
        "# nltk.download('punkt')\n",
        "\n",
        "\n",
        "# def get_response(intents_list, intents_json):\n",
        "#   tag = intents_list[0]['applai'] \n",
        "#   list_of_intents = intents_json['applai']\n",
        "#   for i in list_of_intents:\n",
        "#     if i['tag'] == tag:\n",
        "#       result = random.choice(i['responses'])\n",
        "#       break\n",
        "#   return result\n",
        "# def generate_response(user_input):\n",
        "#     # Preprocess user input\n",
        "#     user_input = user_input.lower()\n",
        "#     tokens = nltk.word_tokenize(user_input)\n",
        "\n",
        "#     # Convert tokens to a sequence of word indices\n",
        "#     word_indices = []\n",
        "#     for word in tokens:\n",
        "#         if word in word_index:\n",
        "#             word_indices.append(word_index[word])\n",
        "#         else:\n",
        "#             word_indices.append(word_index['<unk>'])\n",
        "\n",
        "#     # Pad sequence to max length\n",
        "#     padded_seq = pad_sequences([word_indices], maxlen=max_seq_length,\n",
        "#                                padding='post', truncating='post')\n",
        "\n",
        "#     # Generate response\n",
        "#     response_idx = np.argmax(model.predict(padded_seq), axis=-1)[0]\n",
        "#     response = index_word[response_idx]\n",
        "\n",
        "#     return response\n",
        "\n",
        "# def main():\n",
        "#     i=0\n",
        "#     st.title('Welcome To Applai Chatbot')\n",
        "#     st.sidebar.image(\"ApplAiOnly_Logo.png\", use_column_width=True)\n",
        "#     while True:\n",
        "#       if(i==0):\n",
        "#         user_input = st.text_input('Enter a question:',key=i)\n",
        "#       else:\n",
        "#         user_input = st.text_input('Enter a question:',key=i)\n",
        "#       if st.button('Get answer',key=i):\n",
        "#           x=predict_class(user_input)\n",
        "#           response = get_response(x,intents)\n",
        "#           st.write(response)\n",
        "#       i+=1\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     # main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TscPegtDMerc"
      },
      "outputs": [],
      "source": [
        "#%%writefile app.py\n",
        "\n",
        "\n",
        "# def generate_response(user_input):\n",
        "#     # Preprocess user input\n",
        "#     user_input = user_input.lower()\n",
        "#     tokens = nltk.word_tokenize(user_input)\n",
        "\n",
        "#     # Convert tokens to a sequence of word indices\n",
        "#     word_indices = []\n",
        "#     for word in tokens:\n",
        "#         if word in word_index:\n",
        "#             word_indices.append(word_index[word])\n",
        "#         else:\n",
        "#             word_indices.append(word_index['<unk>'])\n",
        "\n",
        "#     # Pad sequence to max length\n",
        "#     padded_seq = pad_sequences([word_indices], maxlen=max_seq_length,\n",
        "#                                padding='post', truncating='post')\n",
        "\n",
        "#     # Generate response\n",
        "#     response_idx = np.argmax(model.predict(padded_seq), axis=-1)[0]\n",
        "#     response = index_word[response_idx]\n",
        "\n",
        "#     return response\n",
        "\n",
        "# def main():\n",
        "#     st.title('Chatbot')\n",
        "#     user_input = st.text_input('Enter a question:')\n",
        "#     if st.button('Get answer'):\n",
        "#         response = generate_response(user_input)\n",
        "#         st.write(response)\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_mqlY8Ao3Pa"
      },
      "outputs": [],
      "source": [
        "# import streamlit as st\n",
        "# import tensorflow as tf\n",
        "\n",
        "# # Load your chatbot model\n",
        "# model = tf.keras.models.load_model('applai_chatbot_model.model')\n",
        "\n",
        "# # Create a Streamlit app\n",
        "# def app():\n",
        "#     # Create a text input field\n",
        "#     user_input = st.text_input('You:', '')\n",
        "\n",
        "#     # Define the chatbot function\n",
        "#     def chatbot_response(user_input):\n",
        "#         # Preprocess the user's input\n",
        "#         # and generate the chatbot's response\n",
        "#         # using your loaded model\n",
        "#         response = \"Chatbot: \" + \"Your response here\"\n",
        "\n",
        "#         return response\n",
        "\n",
        "#     # Use the Streamlit display functions\n",
        "#     if user_input:\n",
        "#         response = chatbot_response(user_input)\n",
        "#         st.write(response)\n",
        "\n",
        "# # Run the app\n",
        "# if __name__ == '__main__':\n",
        "#     app()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwfSDTXUCy3o"
      },
      "outputs": [],
      "source": [
        "#!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iIX16_qFORa"
      },
      "outputs": [],
      "source": [
        "# %%writefile app.py\n",
        "# import streamlit as st\n",
        "# from streamlit_chat import message\n",
        "\n",
        "# message(\"My message\") \n",
        "# message(\"Hello bot!\", is_user=True)  # align's the message to the right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDUCTQJSE6mB"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py&>/dev/null&"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLqbH997DD96",
        "outputId": "bc9b9ace-579a-48ec-b591-01ae876a199c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2Lyi5BxnZ4GkA1BwlJtM2IWkWHj_7aaWYYnBWL58p5xWNLRq2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-wtH69ABoqt"
      },
      "outputs": [],
      "source": [
        "#!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4t8CRlt7JJdd"
      },
      "outputs": [],
      "source": [
        "#!unzip ngrok-stable-linux-amd64.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ye_iRYWJPFk"
      },
      "outputs": [],
      "source": [
        "get_ipython().system_raw('./ngrok http 8501 &')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8I8G5FAqIBSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JNjsxYWhIBMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "time.sleep(2)"
      ],
      "metadata": {
        "id": "GxwtcE9sIBGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGLVxA6gJeuP",
        "outputId": "0bba5131-9115-4915-f046-54c367e45a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://fd5f-34-173-162-33.ngrok.io\n"
          ]
        }
      ],
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxCRYQMTJjKT",
        "outputId": "852ef852-ecdc-40e9-c7a0-ec7dfc0f9448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.173.162.33:8502\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run /content/app.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3lQzyg1Ih5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da510ec3-7e41-41d1-a2cb-dc8d487addad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: streamlit-chat in /usr/local/lib/python3.8/dist-packages (0.0.2.1)\n",
            "Requirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.8/dist-packages (from streamlit-chat) (1.19.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (6.0.0)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (1.3.5)\n",
            "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (1.0.1)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (2.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (3.1.31)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (5.3.0)\n",
            "Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (23.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (7.1.2)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (1.5.1)\n",
            "Requirement already satisfied: requests>=2.4 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (1.22.4)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (6.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (7.1.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (13.3.1)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (2.8.2)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (1.5)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (4.5.0)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (0.8.0)\n",
            "Requirement already satisfied: semver in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (2.13.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (0.10.2)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (4.2.2)\n",
            "Requirement already satisfied: validators>=0.2 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (0.20.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.63->streamlit-chat) (3.19.6)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=0.63->streamlit-chat) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=0.63->streamlit-chat) (4.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=0.63->streamlit-chat) (2.11.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=0.63->streamlit-chat) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from gitpython!=3.1.19->streamlit>=0.63->streamlit-chat) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=1.4->streamlit>=0.63->streamlit-chat) (3.14.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25->streamlit>=0.63->streamlit-chat) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil->streamlit>=0.63->streamlit-chat) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit>=0.63->streamlit-chat) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit>=0.63->streamlit-chat) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit>=0.63->streamlit-chat) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit>=0.63->streamlit-chat) (2.10)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from rich>=10.11.0->streamlit>=0.63->streamlit-chat) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in /usr/local/lib/python3.8/dist-packages (from rich>=10.11.0->streamlit>=0.63->streamlit-chat) (2.14.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from validators>=0.2->streamlit>=0.63->streamlit-chat) (4.4.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit>=0.63->streamlit-chat) (5.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->altair>=3.2.0->streamlit>=0.63->streamlit-chat) (2.0.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.63->streamlit-chat) (5.12.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.63->streamlit-chat) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.63->streamlit-chat) (0.19.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.8/dist-packages (from markdown-it-py<3.0.0,>=2.1.0->rich>=10.11.0->streamlit>=0.63->streamlit-chat) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit-chat \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5eOC_7f9zH8"
      },
      "outputs": [],
      "source": [
        "#######################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlxPBtWmAb6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a11be1bb-ca7d-4fc5-cb20-7d44b94507d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m140.7/140.7 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m56.2/56.2 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m66.4/66.4 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gBIVGvUDrhD"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHAR6wAaD_8K"
      },
      "outputs": [],
      "source": [
        "def chatbot(input, history=[]):\n",
        "    output = openai_chat(input)\n",
        "    history.append((input, output))\n",
        "    return history, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqngDwYZDgng"
      },
      "outputs": [],
      "source": [
        "gr.Interface(fn = chatbot,\n",
        "             inputs = [\"text\",'state'],\n",
        "             outputs = [\"chatbot\",'state']).launch(debug = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrJF9R-eEL0O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5dAMLKPEReV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}